{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project_Sentiment_analysis_Bert.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO818R1qmJsPgurj9XrwPX9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jung-han-lee/Projects/blob/master/Project_Sentiment_analysis_Bert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gqUa6JUZC3E",
        "colab_type": "text"
      },
      "source": [
        "# 0. Download datasets to Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYL-eoTWv9Fy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "a86aac84-b7f4-4a87-a839-15390a0f2180"
      },
      "source": [
        "%matplotlib inline\n",
        "#manipulation\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "#this is just cool\n",
        "from tqdm import tqdm\n",
        "\n",
        "#visualization\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('ggplot')   #for optimum aesthetics \n",
        "import seaborn as sns\n",
        "\n",
        "#natural language processing\n",
        "import string\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "#stemming/lemmatizing/vectorizing\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "#processing\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#ignore warnings because they are annoying\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3xEyomxZiQY",
        "colab_type": "text"
      },
      "source": [
        "Check device type: To use tensorflow with big data, GPU is essential.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYI06Y1Uryiw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "38013f73-7aa3-4d10-d14b-126d5daa386e"
      },
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[name: \"/device:CPU:0\"\n",
              " device_type: \"CPU\"\n",
              " memory_limit: 268435456\n",
              " locality {\n",
              " }\n",
              " incarnation: 12895683692560764689, name: \"/device:XLA_CPU:0\"\n",
              " device_type: \"XLA_CPU\"\n",
              " memory_limit: 17179869184\n",
              " locality {\n",
              " }\n",
              " incarnation: 11453381397991793378\n",
              " physical_device_desc: \"device: XLA_CPU device\", name: \"/device:XLA_GPU:0\"\n",
              " device_type: \"XLA_GPU\"\n",
              " memory_limit: 17179869184\n",
              " locality {\n",
              " }\n",
              " incarnation: 8226485268698908859\n",
              " physical_device_desc: \"device: XLA_GPU device\", name: \"/device:GPU:0\"\n",
              " device_type: \"GPU\"\n",
              " memory_limit: 14648777152\n",
              " locality {\n",
              "   bus_id: 1\n",
              "   links {\n",
              "   }\n",
              " }\n",
              " incarnation: 16384596572803536325\n",
              " physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Ot-iuE6iLCt",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "9534eff9-acbf-4184-de2d-bab5b95684f9"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-6e4811cb-5592-4ccd-8281-b43ca6d3f83e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-6e4811cb-5592-4ccd-8281-b43ca6d3f83e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"jung1han1lee\",\"key\":\"2989a4b8b1542d70845cd810ca3c9254\"}'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3iSOaIjSiLea",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir -p ~/.kaggle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93doP56iiNa2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp kaggle.json ~/.kaggle/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ob0iKdRuiP5H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eed0368f-37c4-4376-db3d-64389137a14c"
      },
      "source": [
        "!ls ~/.kaggle"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kaggle.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLVK5251iRq6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBqDOf6aiTSo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "1d6aa51b-f9ca-415f-ef7f-1f6ae30ed280"
      },
      "source": [
        "!kaggle kernels list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "ref                                                             title                                              author                lastRunTime          totalVotes  \n",
            "--------------------------------------------------------------  -------------------------------------------------  --------------------  -------------------  ----------  \n",
            "therealcyberlord/coronavirus-covid-19-visualization-prediction  Coronavirus (COVID-19) Visualization & Prediction  Xingyu Bian           2020-08-15 17:26:45         977  \n",
            "allunia/don-t-turn-into-a-smoothie-after-the-shake-up           Don't turn into a Smoothie after the Shake-Up      Laura Fink            2020-08-15 20:36:28         269  \n",
            "fedi1996/house-prices-data-cleaning-viz-and-modeling            House Prices : Data cleaning, viz and modeling     Fedi Ben Messaoud     2020-08-15 23:42:29         109  \n",
            "roshansharma/immigration-to-canada                              Immigration to Canada                              Roshan Sharma         2020-08-15 19:26:36         104  \n",
            "allunia/don-t-turn-into-a-smoothie-image-statistics             Don't turn into a Smoothie - Image Statistics      Laura Fink            2020-08-15 21:12:09          71  \n",
            "carlossouza/probabilistic-machine-learning-a-diff-approach      Probabilistic Machine Learning: A Diff Approach    Carlos Souza          2020-08-16 00:17:48          43  \n",
            "samansiadati/digit-recognizer                                   Digit Recognizer                                   Saman Siadati         2020-08-15 14:56:10          19  \n",
            "isaienkov/covid19-eda-animated-geographical-distribution        COVID19. EDA. Animated geographical distribution.  Kostiantyn Isaienkov  2020-08-15 23:50:41          32  \n",
            "rizqiasm/drug-classification-using-machine-learning-svm         Drug Classification using Machine Learning (SVM)   Rizqi Amaliatus       2020-08-15 21:16:49           4  \n",
            "mekhdigakhramanian/top-7-lb-0-9648-post-processing              Top 7% LB 0.9648 üî• Post-Processing                 Mekhdi Gakhramanian   2020-08-15 21:55:08          13  \n",
            "chanhu/inference-bird-simple-baseline                           [Inference] Bird -- Simple BaseLine                Chanhu                2020-08-15 23:19:17          11  \n",
            "thiagopanini/predicting-the-success-of-a-restaurant             Predicting the Success of a Restaurant ü•ó           Thiago Panini         2020-08-15 15:44:30          41  \n",
            "mitramir5/nlp-visualization-eda-glove-bert                      NLP Visualization, EDA, GloVe, Bert                mitra mirshafiee      2020-08-15 18:10:43          13  \n",
            "vishalkasa/ctscan-corona-vgg16-acc-76                           CTSCAN Corona VGG16 Acc-76%                        Vishal Kasa           2020-08-15 18:58:37           4  \n",
            "somesh24/sea-level-change-time-series                           Sea Level Change: Time Series                      Somesh Sharma         2020-08-15 17:47:42           5  \n",
            "raenish/cheatsheet-text-helper-functions                        Cheatsheet - Text Helper Functions üòç               Raenish David         2020-08-15 05:32:10         516  \n",
            "reverie5/drug-classification-eda-modelling-eval                 Drug Classification: EDA + Modelling + Eval        Rahul Sharma          2020-08-15 16:46:29           6  \n",
            "akashchola/decision-tree-for-classification-regression          Decision Tree For Classification & Regression      Akashi                2020-08-15 17:27:22           5  \n",
            "mrhippo/denoising-mnist-with-autoencoders                       Denoising MNIST with Autoencoders                  Salih Albayrak        2020-08-15 18:35:00           4  \n",
            "sifodhara/the-ultimate-halloween-candy-power-ranking            the ultimate halloween candy power ranking         Dibyajit dhara        2020-08-15 21:03:28           3  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWz87oiHiUlv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "541e4e45-d39b-43e8-9211-238faa11961f"
      },
      "source": [
        "!kaggle datasets download -d datafiniti/consumer-reviews-of-amazon-products"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading consumer-reviews-of-amazon-products.zip to /content\n",
            " 31% 5.00M/16.3M [00:00<00:00, 15.9MB/s]\n",
            "100% 16.3M/16.3M [00:00<00:00, 41.1MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q21qAGtWiWEm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c25336fa-b9c7-40a5-fa92-e64c992d3476"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "consumer-reviews-of-amazon-products.zip  kaggle.json  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36MTt2IziXXu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -q consumer-reviews-of-amazon-products.zip -d ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Ys4k0jmiZK0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "875bc882-e2d4-4aad-dc79-78a80ce07724"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1429_1.csv\n",
            "consumer-reviews-of-amazon-products.zip\n",
            "Datafiniti_Amazon_Consumer_Reviews_of_Amazon_Products.csv\n",
            "Datafiniti_Amazon_Consumer_Reviews_of_Amazon_Products_May19.csv\n",
            "kaggle.json\n",
            "sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zq6U5pjBOemE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv(\"1429_1.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kg31XDjMZ6OS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9d4382f4-5105-4cca-9adb-0e1534b9f9c0"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(34660, 21)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ga2i5S-jB5M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "outputId": "5d908f89-d8e3-42f6-ea30-852394c853af"
      },
      "source": [
        "data.head(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>name</th>\n",
              "      <th>asins</th>\n",
              "      <th>brand</th>\n",
              "      <th>categories</th>\n",
              "      <th>keys</th>\n",
              "      <th>manufacturer</th>\n",
              "      <th>reviews.date</th>\n",
              "      <th>reviews.dateAdded</th>\n",
              "      <th>reviews.dateSeen</th>\n",
              "      <th>reviews.didPurchase</th>\n",
              "      <th>reviews.doRecommend</th>\n",
              "      <th>reviews.id</th>\n",
              "      <th>reviews.numHelpful</th>\n",
              "      <th>reviews.rating</th>\n",
              "      <th>reviews.sourceURLs</th>\n",
              "      <th>reviews.text</th>\n",
              "      <th>reviews.title</th>\n",
              "      <th>reviews.userCity</th>\n",
              "      <th>reviews.userProvince</th>\n",
              "      <th>reviews.username</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AVqkIhwDv8e3D1O-lebb</td>\n",
              "      <td>All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...</td>\n",
              "      <td>B01AHB9CN2</td>\n",
              "      <td>Amazon</td>\n",
              "      <td>Electronics,iPad &amp; Tablets,All Tablets,Fire Ta...</td>\n",
              "      <td>841667104676,amazon/53004484,amazon/b01ahb9cn2...</td>\n",
              "      <td>Amazon</td>\n",
              "      <td>2017-01-13T00:00:00.000Z</td>\n",
              "      <td>2017-07-03T23:33:15Z</td>\n",
              "      <td>2017-06-07T09:04:00.000Z,2017-04-30T00:45:00.000Z</td>\n",
              "      <td>NaN</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>http://reviews.bestbuy.com/3545/5620406/review...</td>\n",
              "      <td>This product so far has not disappointed. My c...</td>\n",
              "      <td>Kindle</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Adapter</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AVqkIhwDv8e3D1O-lebb</td>\n",
              "      <td>All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...</td>\n",
              "      <td>B01AHB9CN2</td>\n",
              "      <td>Amazon</td>\n",
              "      <td>Electronics,iPad &amp; Tablets,All Tablets,Fire Ta...</td>\n",
              "      <td>841667104676,amazon/53004484,amazon/b01ahb9cn2...</td>\n",
              "      <td>Amazon</td>\n",
              "      <td>2017-01-13T00:00:00.000Z</td>\n",
              "      <td>2017-07-03T23:33:15Z</td>\n",
              "      <td>2017-06-07T09:04:00.000Z,2017-04-30T00:45:00.000Z</td>\n",
              "      <td>NaN</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>http://reviews.bestbuy.com/3545/5620406/review...</td>\n",
              "      <td>great for beginner or experienced person. Boug...</td>\n",
              "      <td>very fast</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>truman</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AVqkIhwDv8e3D1O-lebb</td>\n",
              "      <td>All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...</td>\n",
              "      <td>B01AHB9CN2</td>\n",
              "      <td>Amazon</td>\n",
              "      <td>Electronics,iPad &amp; Tablets,All Tablets,Fire Ta...</td>\n",
              "      <td>841667104676,amazon/53004484,amazon/b01ahb9cn2...</td>\n",
              "      <td>Amazon</td>\n",
              "      <td>2017-01-13T00:00:00.000Z</td>\n",
              "      <td>2017-07-03T23:33:15Z</td>\n",
              "      <td>2017-06-07T09:04:00.000Z,2017-04-30T00:45:00.000Z</td>\n",
              "      <td>NaN</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>http://reviews.bestbuy.com/3545/5620406/review...</td>\n",
              "      <td>Inexpensive tablet for him to use and learn on...</td>\n",
              "      <td>Beginner tablet for our 9 year old son.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>DaveZ</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     id  ... reviews.username\n",
              "0  AVqkIhwDv8e3D1O-lebb  ...          Adapter\n",
              "1  AVqkIhwDv8e3D1O-lebb  ...           truman\n",
              "2  AVqkIhwDv8e3D1O-lebb  ...            DaveZ\n",
              "\n",
              "[3 rows x 21 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40ggMlGyIft-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data['label'] = [1 if star >= 4 else 0 for star in data['reviews.rating']];"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xokWX6u5jCAQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "review = data[['reviews.rating', 'reviews.text','reviews.title','label']]\n",
        "review.dropna(inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lwUtxxP6s9k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "b0cb7887-93dd-4e28-871c-e647af564e49"
      },
      "source": [
        "sns.boxplot(review['reviews.rating'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f388e4e9eb8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUSAtljx8Zs3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "6aaafe8b-6649-426d-8cb4-ae3d586de01c"
      },
      "source": [
        "length = [len(text) for text in review['reviews.text']]\n",
        "sns.barplot(review['reviews.rating'],length)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f3874631ba8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xy-OnZyby1ws",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = review[:int(len(review)/2)+1]\n",
        "test = review[int(len(review)/2)+1:]\n",
        "label_list = [0,1] #negative , positive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7fDJ7Vt2rAP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "2343ed09-0d87-47e5-824a-6d200a653e55"
      },
      "source": [
        "review.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>reviews.rating</th>\n",
              "      <th>reviews.text</th>\n",
              "      <th>reviews.title</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.0</td>\n",
              "      <td>This product so far has not disappointed. My c...</td>\n",
              "      <td>Kindle</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.0</td>\n",
              "      <td>great for beginner or experienced person. Boug...</td>\n",
              "      <td>very fast</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5.0</td>\n",
              "      <td>Inexpensive tablet for him to use and learn on...</td>\n",
              "      <td>Beginner tablet for our 9 year old son.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.0</td>\n",
              "      <td>I've had my Fire HD 8 two weeks now and I love...</td>\n",
              "      <td>Good!!!</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>I bought this for my grand daughter when she c...</td>\n",
              "      <td>Fantastic Tablet for kids</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   reviews.rating  ... label\n",
              "0             5.0  ...     1\n",
              "1             5.0  ...     1\n",
              "2             5.0  ...     1\n",
              "3             4.0  ...     1\n",
              "4             5.0  ...     1\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TN0IlCPbDo0k",
        "colab_type": "text"
      },
      "source": [
        "# 1. RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGYklmd79oEJ",
        "colab_type": "text"
      },
      "source": [
        "## 1.1. Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jktt-tCthZIJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "contractions = { \n",
        "\"ain't\": \"am not / are not / is not / has not / have not\",\n",
        "\"aren't\": \"are not / am not\",\n",
        "\"can't\": \"cannot\",\n",
        "\"can't've\": \"cannot have\",\n",
        "\"'cause\": \"because\",\n",
        "\"could've\": \"could have\",\n",
        "\"couldn't\": \"could not\",\n",
        "\"couldn't've\": \"could not have\",\n",
        "\"didn't\": \"did not\",\n",
        "\"doesn't\": \"does not\",\n",
        "\"don't\": \"do not\",\n",
        "\"hadn't\": \"had not\",\n",
        "\"hadn't've\": \"had not have\",\n",
        "\"hasn't\": \"has not\",\n",
        "\"haven't\": \"have not\",\n",
        "\"he'd\": \"he had / he would\",\n",
        "\"he'd've\": \"he would have\",\n",
        "\"he'll\": \"he shall / he will\",\n",
        "\"he'll've\": \"he shall have / he will have\",\n",
        "\"he's\": \"he has / he is\",\n",
        "\"how'd\": \"how did\",\n",
        "\"how'd'y\": \"how do you\",\n",
        "\"how'll\": \"how will\",\n",
        "\"how's\": \"how has / how is / how does\",\n",
        "\"I'd\": \"I had / I would\",\n",
        "\"I'd've\": \"I would have\",\n",
        "\"I'll\": \"I shall / I will\",\n",
        "\"I'll've\": \"I shall have / I will have\",\n",
        "\"I'm\": \"I am\",\n",
        "\"I've\": \"I have\",\n",
        "\"isn't\": \"is not\",\n",
        "\"it'd\": \"it had / it would\",\n",
        "\"it'd've\": \"it would have\",\n",
        "\"it'll\": \"it shall / it will\",\n",
        "\"it'll've\": \"it shall have / it will have\",\n",
        "\"it's\": \"it has / it is\",\n",
        "\"let's\": \"let us\",\n",
        "\"ma'am\": \"madam\",\n",
        "\"mayn't\": \"may not\",\n",
        "\"might've\": \"might have\",\n",
        "\"mightn't\": \"might not\",\n",
        "\"mightn't've\": \"might not have\",\n",
        "\"must've\": \"must have\",\n",
        "\"mustn't\": \"must not\",\n",
        "\"mustn't've\": \"must not have\",\n",
        "\"needn't\": \"need not\",\n",
        "\"needn't've\": \"need not have\",\n",
        "\"o'clock\": \"of the clock\",\n",
        "\"oughtn't\": \"ought not\",\n",
        "\"oughtn't've\": \"ought not have\",\n",
        "\"shan't\": \"shall not\",\n",
        "\"sha'n't\": \"shall not\",\n",
        "\"shan't've\": \"shall not have\",\n",
        "\"she'd\": \"she had / she would\",\n",
        "\"she'd've\": \"she would have\",\n",
        "\"she'll\": \"she shall / she will\",\n",
        "\"she'll've\": \"she shall have / she will have\",\n",
        "\"she's\": \"she has / she is\",\n",
        "\"should've\": \"should have\",\n",
        "\"shouldn't\": \"should not\",\n",
        "\"shouldn't've\": \"should not have\",\n",
        "\"so've\": \"so have\",\n",
        "\"so's\": \"so as / so is\",\n",
        "\"that'd\": \"that would / that had\",\n",
        "\"that'd've\": \"that would have\",\n",
        "\"that's\": \"that has / that is\",\n",
        "\"there'd\": \"there had / there would\",\n",
        "\"there'd've\": \"there would have\",\n",
        "\"there's\": \"there has / there is\",\n",
        "\"they'd\": \"they had / they would\",\n",
        "\"they'd've\": \"they would have\",\n",
        "\"they'll\": \"they shall / they will\",\n",
        "\"they'll've\": \"they shall have / they will have\",\n",
        "\"they're\": \"they are\",\n",
        "\"they've\": \"they have\",\n",
        "\"to've\": \"to have\",\n",
        "\"wasn't\": \"was not\",\n",
        "\"we'd\": \"we had / we would\",\n",
        "\"we'd've\": \"we would have\",\n",
        "\"we'll\": \"we will\",\n",
        "\"we'll've\": \"we will have\",\n",
        "\"we're\": \"we are\",\n",
        "\"we've\": \"we have\",\n",
        "\"weren't\": \"were not\",\n",
        "\"what'll\": \"what shall / what will\",\n",
        "\"what'll've\": \"what shall have / what will have\",\n",
        "\"what're\": \"what are\",\n",
        "\"what's\": \"what has / what is\",\n",
        "\"what've\": \"what have\",\n",
        "\"when's\": \"when has / when is\",\n",
        "\"when've\": \"when have\",\n",
        "\"where'd\": \"where did\",\n",
        "\"where's\": \"where has / where is\",\n",
        "\"where've\": \"where have\",\n",
        "\"who'll\": \"who shall / who will\",\n",
        "\"who'll've\": \"who shall have / who will have\",\n",
        "\"who's\": \"who has / who is\",\n",
        "\"who've\": \"who have\",\n",
        "\"why's\": \"why has / why is\",\n",
        "\"why've\": \"why have\",\n",
        "\"will've\": \"will have\",\n",
        "\"won't\": \"will not\",\n",
        "\"won't've\": \"will not have\",\n",
        "\"would've\": \"would have\",\n",
        "\"wouldn't\": \"would not\",\n",
        "\"wouldn't've\": \"would not have\",\n",
        "\"y'all\": \"you all\",\n",
        "\"y'all'd\": \"you all would\",\n",
        "\"y'all'd've\": \"you all would have\",\n",
        "\"y'all're\": \"you all are\",\n",
        "\"y'all've\": \"you all have\",\n",
        "\"you'd\": \"you had / you would\",\n",
        "\"you'd've\": \"you would have\",\n",
        "\"you'll\": \"you shall / you will\",\n",
        "\"you'll've\": \"you shall have / you will have\",\n",
        "\"you're\": \"you are\",\n",
        "\"you've\": \"you have\"\n",
        "}\n",
        "\n",
        "contractions_re = re.compile('(%s)' % '|'.join(contractions.keys()))\n",
        "def expand_contractions(s, contractions = contractions):\n",
        "    def replace(match):\n",
        "        return contractions[match.group(0)]\n",
        "    return contractions_re.sub(replace, s)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64UKQzuyhZy0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#apply to whole text column\n",
        "review['reviews.text'] = review['reviews.text'].apply(expand_contractions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXUr4hsmwGzu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "6c1882e0-eb4f-4224-925d-a85119449573"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras import Input\n",
        "\n",
        "np.random.seed(34)\n",
        "tf.random.set_seed(34)\n",
        "\n",
        "to_exclude = '*+-/()%\\n[\\\\]{|}^_`~\\t'\n",
        "\n",
        "tokenizer = Tokenizer(filters = to_exclude) # to include punctuation.\n",
        "tokenizer.fit_on_texts(review['reviews.text'])\n",
        "sequences = tokenizer.texts_to_sequences(review['reviews.text'])\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word_index))\n",
        "\n",
        "data = pad_sequences(sequences)\n",
        "\n",
        "print('Shape of data tensor:', data.shape)\n",
        "print('Shape of label tensor:', train['label'].shape)\n",
        "\n",
        "X_train = data[:int(len(review)/2)+1]\n",
        "y_train = train['label']\n",
        "X_test = data[int(len(review)/2)+1:]\n",
        "\n",
        "MAX_SEQUENCE_LENGTH = data.shape[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 14486 unique tokens.\n",
            "Shape of data tensor: (34621, 1887)\n",
            "Shape of label tensor: (17311,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lk4nraYu9y-U",
        "colab_type": "text"
      },
      "source": [
        "## 1.2. GloVe Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAKWN0MMyrIF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "07c03770-4aa5-4250-831d-5233c9fa22c2"
      },
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-08-07 12:20:31--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2020-08-07 12:20:31--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2020-08-07 12:20:31--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‚Äòglove.6B.zip‚Äô\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  1.96MB/s    in 6m 29s  \n",
            "\n",
            "2020-08-07 12:27:01 (2.11 MB/s) - ‚Äòglove.6B.zip‚Äô saved [862182613/862182613]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wQ2V46mysxY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "e6fa480e-daa6-4c4a-f0cb-f7c248118809"
      },
      "source": [
        "!unzip glove*.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "595xaLNDxR5T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "023fa9a5-2866-49a2-c4b5-1d4a9d0a4826"
      },
      "source": [
        "#get GloVe vector embeddings\n",
        "embeddings_index = {}\n",
        "with open('glove.6B.200d.txt','r') as f:\n",
        "    for line in tqdm(f):\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        coefs = np.asarray(values[1:], dtype='float32')\n",
        "        embeddings_index[word] = coefs\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "400000it [00:23, 17308.85it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjX8QjRZ0tCz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EMBEDDING_DIM = 200   #defined by size of GloVe word vector dimensions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXwfu0nN0tsr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0778bb5a-06ff-4a6f-b124-e6a207b9a0ef"
      },
      "source": [
        "#initialize embedding matrix with zeros\n",
        "embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
        "\n",
        "#add glove word encodings to our library\n",
        "for word, i in tqdm(word_index.items()):\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        \n",
        "        #words not found in embedding index will be all-zeros.\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 14486/14486 [00:00<00:00, 439582.75it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEsZlEf_0xMw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f2f1fdba-1695-474c-8979-958507f440ce"
      },
      "source": [
        "print(\"Our embedded matrix is of dimension\", embedding_matrix.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Our embedded matrix is of dimension (14487, 200)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTJEJj3A05X1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Embedding, LSTM, Dense, SpatialDropout1D, Bidirectional, Dropout, Concatenate, LeakyReLU, GRU\n",
        "from keras import Input, Model, regularizers\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import Sequential\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "embedding = Embedding(len(word_index) + 1, EMBEDDING_DIM, weights = [embedding_matrix],\n",
        "                     input_length = MAX_SEQUENCE_LENGTH, trainable = False)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8__YUlF96Uc",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vv9F0vZq96tD",
        "colab_type": "text"
      },
      "source": [
        "## 1.3. LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQ7-GBJX5WzZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_lstm(spatial_dropout, dropout, recurrent_dropout, learning_rate):\n",
        "    \n",
        "    #define inputs\n",
        "    nlp_input = Input(shape = (MAX_SEQUENCE_LENGTH,), name = 'nlp_input')\n",
        "    emb = embedding(nlp_input)\n",
        "    \n",
        "    #add dropout and LSTM layer\n",
        "    emb = SpatialDropout1D(rate = spatial_dropout)(emb) \n",
        "    nlp_out = (Bidirectional(LSTM(100, dropout = dropout, recurrent_dropout = recurrent_dropout,\n",
        "                                 kernel_regularizer = regularizers.l2(1e-4),\n",
        "                                 kernel_initializer = 'orthogonal')))(emb)\n",
        "    \n",
        "    #add meta data and output layer\n",
        "    x = nlp_out\n",
        "    x = Dropout(dropout)(x)\n",
        "    preds = Dense(1, activation='sigmoid', kernel_regularizer = regularizers.l2(1e-4))(x)\n",
        "    \n",
        "    #compile\n",
        "    model = Model(inputs = nlp_input, outputs = preds)\n",
        "    optimizer = Adam(learning_rate = learning_rate)\n",
        "    model.compile(loss = 'binary_crossentropy', optimizer = optimizer, metrics = ['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3N3F-Qb5dYW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "b8657569-aef4-4303-be8a-a34309541b6f"
      },
      "source": [
        "#define initial dropout/learning rates\n",
        "spatial_dropout = 0.2\n",
        "dropout = 0.2\n",
        "recurrent_dropout = 0.2\n",
        "learning_rate = 0.01\n",
        "\n",
        "model1 = create_lstm(spatial_dropout, dropout, recurrent_dropout, learning_rate)\n",
        "model1.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Model: \"functional_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "nlp_input (InputLayer)       [(None, 1887)]            0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 1887, 200)         2897400   \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d_1 (Spatial (None, 1887, 200)         0         \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 200)               240800    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 201       \n",
            "=================================================================\n",
            "Total params: 3,138,401\n",
            "Trainable params: 241,001\n",
            "Non-trainable params: 2,897,400\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zinnr1EH5gUm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "84e79edb-364b-4256-fd61-fc8da0bd25f8"
      },
      "source": [
        "#fit model\n",
        "history1 = model1.fit([X_train],y_train, validation_split = .2,epochs = 3, batch_size = 128,verbose = 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "109/109 [==============================] - 2109s 19s/step - loss: 0.3015 - accuracy: 0.9124 - val_loss: 0.2871 - val_accuracy: 0.9096\n",
            "Epoch 2/3\n",
            "109/109 [==============================] - 2136s 20s/step - loss: 0.2608 - accuracy: 0.9150 - val_loss: 0.2410 - val_accuracy: 0.9137\n",
            "Epoch 3/3\n",
            "109/109 [==============================] - 2112s 19s/step - loss: 0.2511 - accuracy: 0.9145 - val_loss: 0.2265 - val_accuracy: 0.9139\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TuE22HPN-AHS",
        "colab_type": "text"
      },
      "source": [
        "## 1.4. More complecate model : Adding Hidden Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QD0wLScjARK0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_lstm_complex(spatial_dropout, dropout, recurrent_dropout, learning_rate):\n",
        "    #define activation\n",
        "    activation = LeakyReLU(alpha = 0.01)\n",
        "    \n",
        "    #define inputs\n",
        "    nlp_input = Input(shape = (MAX_SEQUENCE_LENGTH,), name = 'nlp_input')\n",
        "    # meta_input_train = Input(shape = (8, ), name = 'meta_train')\n",
        "    emb = embedding(nlp_input)\n",
        "    emb = SpatialDropout1D(dropout)(emb)\n",
        "\n",
        "    #add LSTM layer\n",
        "    nlp_out = (Bidirectional(LSTM(100, dropout = dropout, recurrent_dropout = recurrent_dropout,\n",
        "                                 kernel_initializer = 'orthogonal')))(emb)\n",
        "     \n",
        "    #add meta data    \n",
        "    x = nlp_out\n",
        "    \n",
        "    #add second hidden layer\n",
        "    x = Dropout(dropout)(x)\n",
        "    x = (Dense(100, activation = activation, kernel_regularizer = regularizers.l2(1e-4),\n",
        "              kernel_initializer = 'he_normal'))(x)\n",
        "    \n",
        "    #add output layer\n",
        "    x = Dropout(dropout)(x)\n",
        "    preds = Dense(1, activation='sigmoid', kernel_regularizer = regularizers.l2(1e-4))(x)\n",
        "    \n",
        "    #compile model\n",
        "    model = Model(inputs=nlp_input, outputs = preds)\n",
        "    optimizer = Adam(learning_rate = learning_rate)\n",
        "    model.compile(loss = 'binary_crossentropy', optimizer = optimizer, metrics = ['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ryg_lnJhATuY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "2585a3b3-9a47-48c6-bd97-4587563090d4"
      },
      "source": [
        "#define dropout rates\n",
        "spatial_dropout = .4\n",
        "dropout = .4\n",
        "recurrent_dropout = .4\n",
        "learning_rate = 0.01\n",
        "\n",
        "#define new model\n",
        "model2 = create_lstm_complex(spatial_dropout, dropout, recurrent_dropout, learning_rate)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHdP8pU3AVUy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "956c8b3a-af9c-4bd2-9147-8cd501686483"
      },
      "source": [
        "history2 = model2.fit([X_train], y_train, validation_split = .2,\n",
        "         epochs = 2, batch_size = 128, verbose = 1) #callbacks = [callback]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "109/109 [==============================] - 2116s 19s/step - loss: 0.3168 - accuracy: 0.9109 - val_loss: 0.2948 - val_accuracy: 0.9096\n",
            "Epoch 2/2\n",
            "109/109 [==============================] - 2055s 19s/step - loss: 0.2765 - accuracy: 0.9154 - val_loss: 0.2632 - val_accuracy: 0.9096\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H30K5LM--FAt",
        "colab_type": "text"
      },
      "source": [
        "## 1.5. GRU Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrw1Xytv1LJp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_gru(spatial_dropout, dropout, recurrent_dropout, learning_rate):\n",
        "    #define activation\n",
        "    activation = LeakyReLU(alpha = 0.01)\n",
        "    \n",
        "    #define inputs\n",
        "    nlp_input = Input(shape = (MAX_SEQUENCE_LENGTH,), name = 'nlp_input')\n",
        "    emb = embedding(nlp_input)\n",
        "    emb = SpatialDropout1D(dropout)(emb)\n",
        "\n",
        "    #add LSTM layer\n",
        "    nlp_out = (Bidirectional(GRU(100, dropout = dropout, recurrent_dropout = recurrent_dropout,\n",
        "                                 kernel_initializer = 'orthogonal')))(emb)\n",
        "     \n",
        "    #add meta data    \n",
        "    x = nlp_out\n",
        "    \n",
        "    #add second hidden layer\n",
        "    x = Dropout(dropout)(x)\n",
        "    x = (Dense(100, activation = activation, kernel_regularizer = regularizers.l2(1e-4),\n",
        "              kernel_initializer = 'he_normal'))(x)\n",
        "    \n",
        "    #add output layer\n",
        "    x = Dropout(dropout)(x)\n",
        "    preds = Dense(1, activation='sigmoid', kernel_regularizer = regularizers.l2(1e-4))(x)\n",
        "    \n",
        "    #compile model\n",
        "    model = Model(inputs=nlp_input, outputs = preds)\n",
        "    optimizer = Adam(learning_rate = learning_rate)\n",
        "    model.compile(loss = 'binary_crossentropy', optimizer = optimizer, metrics = ['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQdv_eox1Owl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "13562162-9f30-4509-c5ce-968cded47560"
      },
      "source": [
        "#define dropout rates\n",
        "spatial_dropout = .4\n",
        "dropout = .4\n",
        "recurrent_dropout = .4    \n",
        "learning_rate = 0.01\n",
        "\n",
        "#define new model\n",
        "model3 = create_gru(spatial_dropout, dropout, recurrent_dropout, learning_rate)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_p7g6t11SUF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "b614531f-9e5a-4e8f-dd08-e8d6e069b0da"
      },
      "source": [
        "history3 = model3.fit([X_train], y_train, validation_split = .2,\n",
        "         epochs = 2, batch_size = 128, verbose = 1) #callbacks = [callback]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "109/109 [==============================] - 2118s 19s/step - loss: 0.3132 - accuracy: 0.9132 - val_loss: 0.3871 - val_accuracy: 0.9096\n",
            "Epoch 2/2\n",
            "109/109 [==============================] - 2136s 20s/step - loss: 0.2812 - accuracy: 0.9154 - val_loss: 0.2574 - val_accuracy: 0.9096\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egOB-uy2yYsW",
        "colab_type": "text"
      },
      "source": [
        "# 2. Bert"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugzZVDIZySnY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow-gpu==1.12.2\n",
        "#!pip install tensorflow-gup==1.13.1\n",
        "!pip install tensorflow-hub==0.04\n",
        "\n",
        "\n",
        "!wget https://developer.nvidia.com/compute/cuda/9.0/Prod/local_installers/cuda-repo-ubuntu1604-9-0-local_9.0.176-1_amd64-deb\n",
        "!dpkg -i cuda-repo-ubuntu1604-9-0-local_9.0.176-1_amd64-deb\n",
        "!apt-key add /var/cuda-repo-9-0-local/7fa2af80.pub\n",
        "!apt-get update\n",
        "!apt-get install cuda=9.0.176-1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WeW47QbycFb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "d07b612d-0b8a-4d38-e8bb-2604a519da86"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "from datetime import datetime"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIArjkftEtkK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "OUTPUT_DIR = 'OUTPUT'\n",
        "try:\n",
        "  tf.gfile.DeleteRecursively(OUTPUT_DIR)\n",
        "except:\n",
        "  pass\n",
        "tf.gfile.MakeDirs(OUTPUT_DIR)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6ApQR4eyiu_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "5ef55043-748a-40f7-c447-ee488af437fb"
      },
      "source": [
        "!pip install bert-tensorflow"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bert-tensorflow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/66/7eb4e8b6ea35b7cc54c322c816f976167a43019750279a8473d355800a93/bert_tensorflow-1.0.1-py2.py3-none-any.whl (67kB)\n",
            "\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñâ                           | 10kB 16.8MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                      | 20kB 4.6MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                 | 30kB 6.0MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç            | 40kB 6.3MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé       | 51kB 5.3MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 61kB 5.9MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 71kB 3.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from bert-tensorflow) (1.15.0)\n",
            "Installing collected packages: bert-tensorflow\n",
            "Successfully installed bert-tensorflow-1.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b51Wy0wCylTZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import bert\n",
        "from bert import run_classifier\n",
        "from bert import optimization\n",
        "from bert import tokenization"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7P9A8Lq_yrqx",
        "colab_type": "text"
      },
      "source": [
        "## 2.1. Data Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d27tkn9_yuKt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use the InputExample class from BERT's run_classifier code to create examples from the data\n",
        "train_InputExamples = train.apply(lambda x: bert.run_classifier.InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this example\n",
        "                                                                   text_a = x['reviews.text'], \n",
        "                                                                   text_b = None, \n",
        "                                                                   label = x['label']), axis = 1)\n",
        "\n",
        "test_InputExamples = test.apply(lambda x: bert.run_classifier.InputExample(guid=None, \n",
        "                                                                   text_a = x['reviews.text'], \n",
        "                                                                   text_b = None, \n",
        "                                                                   label = x['label']), axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fg7A7i8W3d7D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "68f6353a-960b-42e0-d312-d338650a60c4"
      },
      "source": [
        "# This is a path to an uncased (all lowercase) version of BERT\n",
        "BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
        "\n",
        "#Create a tokenizer\n",
        "def create_tokenizer_from_hub_module():\n",
        "  \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
        "  with tf.Graph().as_default():\n",
        "    bert_module = hub.Module(BERT_MODEL_HUB)\n",
        "    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
        "    with tf.Session() as sess:\n",
        "      vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"],\n",
        "                                            tokenization_info[\"do_lower_case\"]])\n",
        "      \n",
        "  return bert.tokenization.FullTokenizer(\n",
        "      vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
        "\n",
        "tokenizer = create_tokenizer_from_hub_module()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmRc0vMp3d93",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We'll set sequences to be at most 128 tokens long.\n",
        "MAX_SEQ_LENGTH = 128\n",
        "# Convert our train and test features to InputFeatures that BERT understands.\n",
        "train_features = bert.run_classifier.convert_examples_to_features(train_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
        "test_features = bert.run_classifier.convert_examples_to_features(test_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2m8mnHzEK-e",
        "colab_type": "text"
      },
      "source": [
        "## 2.2. Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFye14FX3eEz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#matic calculation\n",
        "def metric_fn(label_ids, predicted_labels):\n",
        "        accuracy = tf.metrics.accuracy(label_ids, predicted_labels)\n",
        "        f1_score = tf.contrib.metrics.f1_score(\n",
        "            label_ids,\n",
        "            predicted_labels)\n",
        "        auc = tf.metrics.auc(\n",
        "            label_ids,\n",
        "            predicted_labels)\n",
        "        recall = tf.metrics.recall(\n",
        "            label_ids,\n",
        "            predicted_labels)\n",
        "        precision = tf.metrics.precision(\n",
        "            label_ids,\n",
        "            predicted_labels) \n",
        "        true_pos = tf.metrics.true_positives(\n",
        "            label_ids,\n",
        "            predicted_labels)\n",
        "        true_neg = tf.metrics.true_negatives(\n",
        "            label_ids,\n",
        "            predicted_labels)   \n",
        "        false_pos = tf.metrics.false_positives(\n",
        "            label_ids,\n",
        "            predicted_labels)  \n",
        "        false_neg = tf.metrics.false_negatives(\n",
        "            label_ids,\n",
        "            predicted_labels)\n",
        "        return {\n",
        "            \"eval_accuracy\": accuracy,\n",
        "            \"f1_score\": f1_score,\n",
        "            \"auc\": auc,\n",
        "            \"precision\": precision,\n",
        "            \"recall\": recall,\n",
        "            \"true_positives\": true_pos,\n",
        "            \"true_negatives\": true_neg,\n",
        "            \"false_positives\": false_pos,\n",
        "            \"false_negatives\": false_neg\n",
        "        }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DF8zdxtj5K6j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model(is_predicting, input_ids, input_mask, segment_ids, labels,\n",
        "                 num_labels):\n",
        "  \"\"\"Creates a classification model.\"\"\"\n",
        "\n",
        "  bert_module = hub.Module(\n",
        "      BERT_MODEL_HUB,\n",
        "      trainable=True)\n",
        "  bert_inputs = dict(\n",
        "      input_ids=input_ids,\n",
        "      input_mask=input_mask,\n",
        "      segment_ids=segment_ids)\n",
        "  bert_outputs = bert_module(\n",
        "      inputs=bert_inputs,\n",
        "      signature=\"tokens\",\n",
        "      as_dict=True)\n",
        "\n",
        "  # Use \"pooled_output\" for classification tasks on an entire sentence.\n",
        "  # Use \"sequence_outputs\" for token-level output.\n",
        "  output_layer = bert_outputs[\"pooled_output\"]\n",
        "\n",
        "  hidden_size = output_layer.shape[-1].value\n",
        "\n",
        "  # Create our own layer \n",
        "  output_weights = tf.get_variable(\n",
        "      \"output_weights\", [num_labels, hidden_size],\n",
        "      initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
        "\n",
        "  output_bias = tf.get_variable(\n",
        "      \"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n",
        "\n",
        "  with tf.variable_scope(\"loss\"):\n",
        "\n",
        "    # Dropout helps prevent overfitting\n",
        "    output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)\n",
        "\n",
        "    logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n",
        "    logits = tf.nn.bias_add(logits, output_bias)\n",
        "    log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
        "\n",
        "    # Convert labels into one-hot encoding\n",
        "    one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n",
        "\n",
        "    predicted_labels = tf.squeeze(tf.argmax(log_probs, axis=-1, output_type=tf.int32))\n",
        "    # If we're predicting, we want predicted labels and the probabiltiies.\n",
        "    if is_predicting:\n",
        "      return (predicted_labels, log_probs)\n",
        "\n",
        "    # If we're train/eval, compute loss between predicted and actual label\n",
        "    per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n",
        "    loss = tf.reduce_mean(per_example_loss)\n",
        "    return (loss, predicted_labels, log_probs)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vk4dODN5K92",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model_fn_builder actually creates our model function\n",
        "# using the passed parameters for num_labels, learning_rate, etc.\n",
        "def model_fn_builder(num_labels, learning_rate, num_train_steps,\n",
        "                     num_warmup_steps):\n",
        "  \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\n",
        "  def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n",
        "    \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n",
        "\n",
        "    input_ids = features[\"input_ids\"]\n",
        "    input_mask = features[\"input_mask\"]\n",
        "    segment_ids = features[\"segment_ids\"]\n",
        "    label_ids = features[\"label_ids\"]\n",
        "\n",
        "    is_predicting = (mode == tf.estimator.ModeKeys.PREDICT)\n",
        "    \n",
        "    # TRAIN and EVAL\n",
        "    if not is_predicting:\n",
        "\n",
        "      (loss, predicted_labels, log_probs) = create_model(\n",
        "        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
        "\n",
        "      train_op = bert.optimization.create_optimizer(\n",
        "          loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu=False)\n",
        "\n",
        "      # Calculate evaluation metrics.\n",
        "      eval_metrics = metric_fn(label_ids, predicted_labels)\n",
        "\n",
        "      if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "        return tf.estimator.EstimatorSpec(mode=mode,\n",
        "          loss=loss,\n",
        "          train_op=train_op)\n",
        "      else:\n",
        "          return tf.estimator.EstimatorSpec(mode=mode,\n",
        "            loss=loss,\n",
        "            eval_metric_ops=eval_metrics)\n",
        "    else:\n",
        "      (predicted_labels, log_probs) = create_model(\n",
        "        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
        "\n",
        "      predictions = {\n",
        "          'probabilities': log_probs,\n",
        "          'labels': predicted_labels\n",
        "      }\n",
        "      return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
        "\n",
        "  # Return the actual model function in the closure\n",
        "  return model_fn\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmUhns45EZaH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compute train and warmup steps from batch size\n",
        "# These hyperparameters are copied from this colab notebook (https://colab.sandbox.google.com/github/tensorflow/tpu/blob/master/tools/colab/bert_finetuning_with_cloud_tpus.ipynb)\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 2e-5\n",
        "NUM_TRAIN_EPOCHS = 3.0\n",
        "# Warmup is a period of time where the learning rate \n",
        "# is small and gradually increases--usually helps training.\n",
        "WARMUP_PROPORTION = 0.1\n",
        "# Model configs\n",
        "SAVE_CHECKPOINTS_STEPS = 500\n",
        "SAVE_SUMMARY_STEPS = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPj3viWnEZeF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compute # train and warmup steps from batch size\n",
        "num_train_steps = int(len(train_features) / BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
        "num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIS7qBgvEc6Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Specify outpit directory and number of checkpoint steps to save\n",
        "run_config = tf.estimator.RunConfig(\n",
        "    model_dir=OUTPUT_DIR,\n",
        "    save_summary_steps=SAVE_SUMMARY_STEPS,\n",
        "    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nUr-7mZEc9W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "60dba4ba-3f87-4044-f9ea-e5a58a5f9a5f"
      },
      "source": [
        "model_fn = model_fn_builder(\n",
        "  num_labels=len(label_list),\n",
        "  learning_rate=LEARNING_RATE,\n",
        "  num_train_steps=num_train_steps,\n",
        "  num_warmup_steps=num_warmup_steps)\n",
        "\n",
        "estimator = tf.estimator.Estimator(\n",
        "  model_fn=model_fn,\n",
        "  config=run_config,\n",
        "  params={\"batch_size\": BATCH_SIZE})\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': 'OUTPUT', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 500, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7ff9efd36c50>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': 'OUTPUT', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 500, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7ff9efd36c50>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Mv9KgWyExVw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create an input function for training. drop_remainder = True for using TPUs.\n",
        "train_input_fn = bert.run_classifier.input_fn_builder(\n",
        "    features=train_features,\n",
        "    seq_length=MAX_SEQ_LENGTH,\n",
        "    is_training=True,\n",
        "    drop_remainder=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYFhrnBWExZz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "da1956b8-4453-4cce-98e7-88b75f1a6f57"
      },
      "source": [
        "print(f'Beginning Training!')\n",
        "current_time = datetime.now()\n",
        "estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
        "print(\"Training took time \", datetime.now() - current_time)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Beginning Training!\n",
            "INFO:tensorflow:Skipping training since max_steps has already saved.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Skipping training since max_steps has already saved.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training took time  0:00:00.015490\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avGoFc8DLThu",
        "colab_type": "text"
      },
      "source": [
        "The BERT model has the highest accuracy!!!\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnmv-VVnE54M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_input_fn = run_classifier.input_fn_builder(\n",
        "    features=test_features,\n",
        "    seq_length=MAX_SEQ_LENGTH,\n",
        "    is_training=False,\n",
        "    drop_remainder=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvhaGAqLE57H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        },
        "outputId": "f6c9ea05-00dc-4bee-fc74-173099eaa24a"
      },
      "source": [
        "estimator.evaluate(input_fn=test_input_fn, steps=None)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Starting evaluation at 2020-07-31-17:28:24\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Starting evaluation at 2020-07-31-17:28:24\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from OUTPUT/model.ckpt-1622\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from OUTPUT/model.ckpt-1622\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished evaluation at 2020-07-31-17:33:39\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished evaluation at 2020-07-31-17:33:39\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving dict for global step 1622: auc = 0.618464, eval_accuracy = 0.96019644, f1_score = 0.979453, false_negatives = 61.0, false_positives = 628.0, global_step = 1622, loss = 0.20460203, precision = 0.96316713, recall = 0.9962992, true_negatives = 199.0, true_positives = 16422.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving dict for global step 1622: auc = 0.618464, eval_accuracy = 0.96019644, f1_score = 0.979453, false_negatives = 61.0, false_positives = 628.0, global_step = 1622, loss = 0.20460203, precision = 0.96316713, recall = 0.9962992, true_negatives = 199.0, true_positives = 16422.0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1622: OUTPUT/model.ckpt-1622\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1622: OUTPUT/model.ckpt-1622\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'auc': 0.618464,\n",
              " 'eval_accuracy': 0.96019644,\n",
              " 'f1_score': 0.979453,\n",
              " 'false_negatives': 61.0,\n",
              " 'false_positives': 628.0,\n",
              " 'global_step': 1622,\n",
              " 'loss': 0.20460203,\n",
              " 'precision': 0.96316713,\n",
              " 'recall': 0.9962992,\n",
              " 'true_negatives': 199.0,\n",
              " 'true_positives': 16422.0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3E7E9pyE8YY",
        "colab_type": "text"
      },
      "source": [
        "# 3. New Section : Let's use the test data to see how the best model(BERT) works."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibJN9XT-FfzX",
        "colab_type": "text"
      },
      "source": [
        "Now let's write code to make predictions on new sentences:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Na9wn7W15LEs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getPrediction(in_sentences):\n",
        "  labels = [\"Negative\", \"Positive\"]\n",
        "  input_examples = [run_classifier.InputExample(guid=\"\", text_a = x, text_b = None, label = 0) for x in in_sentences] # here, \"\" is just a dummy label\n",
        "  input_features = run_classifier.convert_examples_to_features(input_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
        "  predict_input_fn = run_classifier.input_fn_builder(features=input_features, seq_length=MAX_SEQ_LENGTH, is_training=False, drop_remainder=False)\n",
        "  predictions = estimator.predict(predict_input_fn)\n",
        "  return [(sentence, prediction['probabilities'], labels[prediction['labels']]) for sentence, prediction in zip(in_sentences, predictions)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62v_AGYsFkhi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_sentences = [\n",
        "  \"it makes error everytime.\",\n",
        "  \"Color is way too bright. I won't buy it again\",\n",
        "  \"Too big to me. I recommend it to tall guys like 6.0\",\n",
        "  \"Too big to me\",\n",
        "  \"Not fully satisfied. So it's okay\"\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXBm-reSFnMj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = getPrediction(pred_sentences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChuhE89oFklo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "e368a2b1-5934-4693-cc57-37f2ad0506d4"
      },
      "source": [
        "predictions"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('it makes error everytime.',\n",
              "  array([-0.04375695, -3.1509042 ], dtype=float32),\n",
              "  'Negative'),\n",
              " (\"Color is way too bright. I won't buy it again\",\n",
              "  array([-0.01572119, -4.1605964 ], dtype=float32),\n",
              "  'Negative'),\n",
              " ('Too big to me. I recommend it to tall guys like 6.0',\n",
              "  array([-5.403069e+00, -4.512959e-03], dtype=float32),\n",
              "  'Positive'),\n",
              " ('Too big to me',\n",
              "  array([-2.7515728 , -0.06595545], dtype=float32),\n",
              "  'Positive'),\n",
              " (\"Not fully satisfied. So it's okay\",\n",
              "  array([-0.20968884, -1.6651435 ], dtype=float32),\n",
              "  'Negative')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    }
  ]
}